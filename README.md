# â™»ï¸ EcoSort AI: Classificador de ResÃ­duos com Transfer Learning

> **Status:** ConcluÃ­do âœ…  
> **Modelo:** ResNet50 (Transfer Learning)  
> **AcurÃ¡cia Final:** 90.79% (TrashNet)  
> **Arquitetura:** MLOps Pipeline Completo (Model + API + Frontend)

O **EcoSort AI** Ã© uma soluÃ§Ã£o completa de VisÃ£o Computacional para automaÃ§Ã£o da reciclagem. O projeto vai alÃ©m do treinamento do modelo, implementando um **pipeline de MLOps** com API de inferÃªncia e interface de usuÃ¡rio, focando em robustez contra viÃ©s de contexto.

O sistema aborda desafios reais de engenharia, como **datasets desbalanceados**, **viÃ©s de contexto** (background bias) e **training-serving skew**, demonstrando a diferenÃ§a entre performance em ambiente controlado e aplicaÃ§Ã£o no mundo real.

![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![ResNet](https://img.shields.io/badge/Model-ResNet50-blue?style=for-the-badge)
![Status](https://img.shields.io/badge/TrashNet-SOTA-success?style=for-the-badge)

---

## ğŸ—ï¸ Arquitetura do Sistema

O projeto foi estruturado simulando um **ambiente de produÃ§Ã£o real** com trÃªs componentes integrados:

### ğŸ”¹ Stack Completa

1. **NÃºcleo de IA (PyTorch):** Treinamento com Transfer Learning e correÃ§Ã£o de desbalanceamento
2. **Backend (FastAPI):** API RESTful que serve o modelo, tratando imagens (bytes) e normalizaÃ§Ã£o
3. **Frontend (Streamlit):** Interface web amigÃ¡vel para upload e classificaÃ§Ã£o em tempo real

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
waste-classifier-pytorch/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # API FastAPI
â”‚   â”œâ”€â”€ frontend.py      # Interface Streamlit
â”‚   â””â”€â”€ utils.py         # LÃ³gica de InferÃªncia e PrÃ©-processamento
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ notebook.ipynb   # Treinamento e AnÃ¡lise
â”‚
â”œâ”€â”€ models/              # Modelos salvos
â”‚
â”œâ”€â”€ assets/              # Imagens de demonstraÃ§Ã£o e matriz de confusÃ£o
â”‚
â”œâ”€â”€ TrashNet/            # Dataset (baixar separadamente)
â”‚
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â”‚
â””â”€â”€ README.md            # Este arquivo
```

---

## ğŸ› ï¸ Tecnologias Utilizadas

### ğŸ”¹ Machine Learning

- **PyTorch:** ConstruÃ§Ã£o do modelo e treinamento
- **Torchvision:** Transfer Learning e transformaÃ§Ãµes
- **Scikit-learn:** MÃ©tricas de avaliaÃ§Ã£o e split estratificado

### ğŸ”¹ Backend & API

- **FastAPI:** API RESTful de alta performance
- **Uvicorn:** Servidor ASGI para FastAPI
- **Pillow:** Processamento de imagens

### ğŸ”¹ Frontend

- **Streamlit:** Interface web interativa
- **Requests:** ComunicaÃ§Ã£o com a API

### ğŸ”¹ VisualizaÃ§Ã£o & AnÃ¡lise

- **Matplotlib:** VisualizaÃ§Ãµes e matriz de confusÃ£o
- **Pandas/NumPy:** ManipulaÃ§Ã£o de dados

---

## ğŸ“Š Sobre o Dataset (TrashNet)

Utilizei o dataset padrÃ£o da indÃºstria, **TrashNet**, contendo 2.527 imagens divididas em 6 categorias.

### ğŸ”¹ Classes

- ğŸ“¦ **Cardboard** (PapelÃ£o)
- ğŸ· **Glass** (Vidro)
- ğŸ”© **Metal**
- ğŸ“„ **Paper** (Papel)
- ğŸ§´ **Plastic** (PlÃ¡stico)
- ğŸ—‘ï¸ **Trash** (Lixo Geral)

### ğŸ”¹ Desafio: Dataset Desbalanceado

O dataset original apresenta forte desbalanceamento (muito papel, pouco lixo geral), o que pode causar viÃ©s no modelo.

#### ğŸ“Œ SoluÃ§Ãµes Implementadas:

**1. Split Estratificado**
- MantÃ©m a proporÃ§Ã£o de classes em Treino/ValidaÃ§Ã£o/Teste
- Garante que todas as classes estejam representadas adequadamente

**2. Balanceamento via Pesos**
- `WeightedRandomSampler` durante o treinamento
- Pesos na Loss Function calculados inversamente Ã  frequÃªncia das classes
- Penaliza mais o modelo quando erra classes minoritÃ¡rias (como `Trash`)

---

## ğŸ§  Arquitetura do Modelo

Utilizei **Transfer Learning** para contornar a escassez de dados e acelerar a convergÃªncia.

### ğŸ”¹ Backbone

- **ResNet50** prÃ©-treinada na ImageNet
- Feature Extractor congelado (pesos mantidos fixos)
- Aproveita representaÃ§Ãµes visuais aprendidas de 1.4 milhÃµes de imagens

### ğŸ”¹ Classificador Customizado

```python
classifier = nn.Sequential(
    nn.Linear(2048, 1024),
    nn.ReLU(),
    nn.Dropout(0.5),        # Crucial para regularizaÃ§Ã£o
    nn.Linear(1024, 6)      # 6 classes de resÃ­duos
)
```

**Dropout (0.5)** foi essencial para evitar overfitting dado o tamanho reduzido do dataset.

---

## ğŸ“ˆ Resultados em Ambiente Controlado

O modelo atingiu resultados competitivos com o Estado da Arte para este dataset.

| MÃ©trica | Valor |
|---------|-------|
| **AcurÃ¡cia (Teste)** | **90.53%** |
| **Ã‰pocas Treinadas** | 11 (Early Stopping) |
| **Tempo de Treino** | ~10 minutos (GPU T4) |

### ğŸ”¹ AnÃ¡lise da Matriz de ConfusÃ£o
Abaixo, a Matriz de ConfusÃ£o mostrando os acertos por classe:

<div align="center">
  <img src="./assets/confusion_matrix.png" alt="Matriz de ConfusÃ£o" width="600">
  <p><em>Figura 1: Matriz de ConfusÃ£o do modelo no conjunto de teste</em></p>
</div>

**Pontos Fortes:**
- âœ… **Trash (Lixo Geral):** 19/20 acertos - estratÃ©gia de pesos funcionou perfeitamente
- âœ… Excelente distinÃ§Ã£o entre **Papel** e **PapelÃ£o**

**Desafios Identificados:**
- âš ï¸ Leve confusÃ£o entre **Vidro** e **PlÃ¡stico** devido Ã  transparÃªncia e reflexos similares (esperado e reduzido)
- âš ï¸ Algumas confusÃµes em materiais com textura ambÃ­gua

---

## ğŸ§ª Case Study: O Desafio do Mundo Real

A maior conquista deste projeto foi **corrigir o Training-Serving Skew**. ApÃ³s validar o modelo com 90% de precisÃ£o no dataset (fundo branco uniforme), realizamos testes com **fotos reais de smartphone** para avaliar a robustez em condiÃ§Ãµes nÃ£o controladas.

### ğŸš¨ Descoberta: ViÃ©s de Contexto Significativo

**Problema detectado:** O modelo aprendeu a associar o **fundo** da imagem Ã  classe, nÃ£o apenas o objeto.

**SoluÃ§Ã£o implementada:** AplicaÃ§Ã£o de **NormalizaÃ§Ã£o da ImageNet** (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`) tanto no treino quanto na inferÃªncia, forÃ§ando o modelo a focar em caracterÃ­sticas do objeto.
---

### ğŸ“± Caso 1: O "PapelÃ£o" de Madeira

**Experimento Inicial (Antes da CorreÃ§Ã£o):**
- Fotografamos uma **folha de papel branca** sobre um **piso de madeira**

**Resultado Anterior:**
- ğŸ·ï¸ **Classe Real:** Paper
- ğŸ§  **PrediÃ§Ã£o:** `CARDBOARD` (99.9% de confianÃ§a) âŒ

**DiagnÃ³stico:**
- O modelo associou a cor marrom e textura do chÃ£o Ã  classe PapelÃ£o
- Ignorou completamente a cor branca e textura lisa do papel
- **Shortcut learning:** Aprendeu atalho visual (fundo) em vez da caracterÃ­stica real (objeto)

**ApÃ³s CorreÃ§Ã£o:**
- Sistema agora aplica normalizaÃ§Ã£o adequada na inferÃªncia
- ViÃ©s de fundo drasticamente reduzido âœ…

---

### ğŸŒ¿ Caso 2: A Garrafa de PlÃ¡stico na Grama

**Experimento (Teste Extremo):**
- Fotografamos uma **garrafa de plÃ¡stico transparente** jogada na **grama** (fundo nunca visto no treino)

**Resultado:**
- ğŸ·ï¸ **Classe Real:** Plastic
- ğŸ§  **PrediÃ§Ã£o:** `PLASTIC` (62.18% de confianÃ§a) âœ…

**AnÃ¡lise:**
- A confianÃ§a foi menor (o que Ã© **honesto e esperado**)
- A decisÃ£o foi **correta**
- O modelo aprendeu a forma do objeto, **ignorando o fundo verde**
- Demonstra robustez contra ambientes nÃ£o controlados

---

### ğŸ¾ Caso 3: O Vidro com Fundo Complexo

**Experimento:**
- Fotografamos uma **garrafa de vidro** em ambiente complexo com fundo variado

**Resultado Inicial (Antes da CorreÃ§Ã£o):**
- ğŸ·ï¸ **Classe Real:** Glass
- ğŸ§  **PrediÃ§Ã£o:** `PLASTIC` (83% de confianÃ§a) âŒ
- **Problema:** Modelo confundia reflexos com caracterÃ­sticas de plÃ¡stico

**Resultado Atual (ApÃ³s CorreÃ§Ã£o):**
- ğŸ§  **PrediÃ§Ã£o (Fundo Complexo):** `GLASS` (81.93% de confianÃ§a) âœ…
- ğŸ§  **PrediÃ§Ã£o (Fundo Branco):** `GLASS` (98.46% de confianÃ§a) âœ…

**ConclusÃ£o:**
- O modelo mantÃ©m coerÃªncia da classificaÃ§Ã£o em ambientes nÃ£o controlados
- NormalizaÃ§Ã£o correta foi **crÃ­tica** para generalizaÃ§Ã£o

---

## ğŸ”¬ AnÃ¡lise TÃ©cnica do ViÃ©s e SoluÃ§Ã£o

### Por que o viÃ©s acontecia?

1. **Dataset HomogÃªneo:** TrashNet possui todas as imagens com fundo branco/neutro
2. **Feature Learning Incorreto:** A rede aprendia que fundo marrom/texturizado = PapelÃ£o
3. **AusÃªncia de Variabilidade:** NÃ£o hÃ¡ exemplos de papel em fundos escuros ou papelÃ£o em fundos claros
4. **Training-Serving Skew:** DiferenÃ§a entre prÃ©-processamento no treino vs. inferÃªncia

### Como corrigi?

**SoluÃ§Ã£o Principal: NormalizaÃ§Ã£o da ImageNet**
```python
transforms.Normalize(
    mean=[0.485, 0.456, 0.406],  # Valores da ImageNet
    std=[0.229, 0.224, 0.225]
)
```

**AplicaÃ§Ã£o consistente em:**
- âœ… Pipeline de treinamento
- âœ… Pipeline de validaÃ§Ã£o
- âœ… API de inferÃªncia (FastAPI)
- âœ… Frontend (Streamlit)

**Resultado:** ReduÃ§Ã£o drÃ¡stica do viÃ©s de fundo, permitindo generalizaÃ§Ã£o para ambientes reais.

## ğŸš€ Roadmap: PrÃ³ximos Passos para ProduÃ§Ã£o

Para tornar o EcoSort AI ainda mais robusto para aplicaÃ§Ã£o em larga escala:

### ğŸ”¹ 1. SegmentaÃ§Ã£o PrÃ©via

Implementar um modelo de segmentaÃ§Ã£o (ex: **U-Net** ou **Mask R-CNN**) para:
- Isolar o objeto do fundo
- Remover background antes da classificaÃ§Ã£o
- Pipeline de dois estÃ¡gios: SegmentaÃ§Ã£o â†’ ClassificaÃ§Ã£o

### ğŸ”¹ 2. Data Augmentation AvanÃ§ado

- **Mosaic Augmentation:** Inserir fundos aleatÃ³rios durante o treino
- **CutOut:** Mascarar partes da imagem para forÃ§ar o modelo a nÃ£o depender de contexto
- **MixUp:** Misturar imagens de diferentes classes

### ğŸ”¹ 3. Dataset Expandido

- Coletar imagens com fundos diversos (madeira, concreto, grama, etc.)
- Incluir variaÃ§Ãµes de iluminaÃ§Ã£o (dia, noite, sombra)
- Adicionar objetos em diferentes Ã¢ngulos e distÃ¢ncias

### ğŸ”¹ 4. Domain Adaptation

- Treinar em imagens sintÃ©ticas com fundos variados
- Aplicar tÃ©cnicas de **Domain Randomization**
- Fine-tuning em dados reais coletados de usuÃ¡rios

### ğŸ”¹ 5. Deploy em ProduÃ§Ã£o

- ContainerizaÃ§Ã£o com **Docker**
- Deploy em nuvem (AWS/GCP/Azure)
- Monitoramento de drift do modelo
- Sistema de feedback para retreinamento contÃ­nuo

---

## âš™ï¸ Como Executar

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone https://github.com/oalvarobraz/eco-sort-ai.git
cd eco-sort-ai
```

### 2ï¸âƒ£ Baixe o dataset

Acesse o [TrashNet Dataset](https://www.kaggle.com/datasets/feyzazkefe/trashnet/code) e extraia `TrashNet/`

### 3ï¸âƒ£ Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Execute o notebook (opcional)

```bash
jupyter notebook src/notebook.ipynb
```

### 5ï¸âƒ£ Inicie o Backend (API)

Em um terminal, inicie o servidor FastAPI:

```bash
uvicorn app.main:app --reload
```

O servidor rodarÃ¡ em `http://127.0.0.1:8000`

### 6ï¸âƒ£ Inicie o Frontend

Em outro terminal, inicie o Streamlit:

```bash
streamlit run app/frontend.py
```

O navegador abrirÃ¡ automaticamente. Basta arrastar uma imagem para classificar! ğŸ‰

---

## ğŸ“¦ DependÃªncias Principais

```text
# Deep Learning
torch>=2.0.0
torchvision>=0.15.0

# Backend
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
python-multipart>=0.0.6

# Frontend
streamlit>=1.28.0
requests>=2.31.0

# Processamento
pillow>=10.0.0
numpy>=1.24.0
pandas>=2.0.0

# VisualizaÃ§Ã£o
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
```

---

## âœ… Principais Aprendizados

- **Transfer Learning:** ResNet50 acelerou drasticamente o treinamento e melhorou a generalizaÃ§Ã£o
- **Balanceamento de Classes:** Pesos na loss function foram cruciais para lidar com desbalanceamento
- **Training-Serving Skew:** NormalizaÃ§Ã£o consistente entre treino e inferÃªncia Ã© **crÃ­tica**
- **ViÃ©s de Dataset:** IdentificaÃ§Ã£o prÃ¡tica de shortcut learning e suas implicaÃ§Ãµes em produÃ§Ã£o
- **Gap Lab â†’ Real:** MÃ©tricas em ambiente controlado nÃ£o garantem performance em aplicaÃ§Ã£o real
- **MLOps Pipeline:** ImplementaÃ§Ã£o de API + Frontend simula ambiente de produÃ§Ã£o real
- **ConfianÃ§a do Modelo:** Importante monitorar nÃ£o apenas a classe predita, mas tambÃ©m a confianÃ§a

---

## ğŸ¯ ConclusÃ£o

O **EcoSort AI** demonstra tanto o **potencial** quanto as **limitaÃ§Ãµes** de Deep Learning aplicado a problemas reais, e como superÃ¡-las atravÃ©s de engenharia cuidadosa.

**Conquistas:**
- âœ… 90.79% de acurÃ¡cia em ambiente controlado
- âœ… Robustez em ambientes nÃ£o controlados apÃ³s correÃ§Ã£o de viÃ©s
- âœ… Pipeline MLOps completo (Modelo + API + Frontend)
- âœ… IdentificaÃ§Ã£o e correÃ§Ã£o de training-serving skew

**LiÃ§Ãµes CrÃ­ticas:**
1. **Dataset diversificado** que represente o ambiente de produÃ§Ã£o
2. **PrÃ©-processamento consistente** entre treino e inferÃªncia
3. **ValidaÃ§Ã£o alÃ©m das mÃ©tricas** - testar em cenÃ¡rios nÃ£o controlados
4. **Monitoramento de confianÃ§a** - nÃ£o apenas a classe predita

Este projeto serve como estudo de caso valioso sobre a diferenÃ§a entre **validaÃ§Ã£o de laboratÃ³rio** e **robustez no mundo real**, e como construir sistemas de ML verdadeiramente confiÃ¡veis.

---

## ğŸ“Œ Autor

**Ãlvaro Braz**

Projeto desenvolvido para fins de **estudo, pesquisa e portfÃ³lio profissional em VisÃ£o Computacional, Deep Learning e MLOps**.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ™ Agradecimentos

- **TrashNet Dataset:** Gary Thung & Mindy Yang
- **PyTorch Team:** Pela framework excepcional
- **FastAPI & Streamlit:** Por tornarem deploy de ML acessÃ­vel
- **Comunidade de Deep Learning:** Pelas discussÃµes sobre domain adaptation e robustez de modelos